Test Suite based on TimeML Guidelines
This test suite is based on example sentences extracted from TimeML 1.2.1 annotation guidelines. The original sentences were translated to the Simple Time Format (sft) and appear in the column "TimeML". The translation is not 1:1 due to small issues in the original analysis. See comments. For more details about the source of the sentences see the TimeML annotation guidelines PDF under src/main/resources. 
In most cases the TimeML analyses are incomparable to Caevo's output, either because TimeML analyses are not densed (i.e. not all possible links between events and timexs are created), or because they include more details than Caevo produces.  For example, when one timex is created based on another, the TimeML annotation mentions that using the anchorTimeID attribute, but this is not implemented in Caevo. As a result, we transformed the TimeML analyses into Gold analyses which are comparable to Caevo's output. These appear in the column 'Gold'.
The Gold analysis of each sentence is what caevo is required to create in order to count as well-performing. However, due to some known limitations of Caevo, it is expected that some events/timexs/links will be missed or created incorrectly. This situation is pretty stable and in order to have a way of verifying that Caevo's behavior is persistent we created the expected version for each sentence, shown in the 'Expected' column. This is what we expect Caevo to produce at the moment. 
The test suite runs as part of the building process of Caevo and verifies that all test cases are annotated as written in their cooresponding 'Expected' versions. The suite also produces a score for each test, indicating the precision, recall and F1 measures that show how close it is to the gold version. See the 'Score' column.
The rest of this file details the test cases and their status. 
